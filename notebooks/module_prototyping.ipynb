{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import youtube_dl\n",
    "import os\n",
    "class Downloader:\n",
    "    class MyLogger(object):\n",
    "        def debug(self, msg):\n",
    "            pass\n",
    "        def warning(self, msg):\n",
    "            pass\n",
    "        def error(self, msg):\n",
    "            print(msg)\n",
    "\n",
    "    @classmethod\n",
    "    def download(cls, url, filename):\n",
    "        ydl_opts = {\n",
    "            'format': 'bestaudio/best',\n",
    "            'outtmpl': filename,\n",
    "            'postprocessors': [{\n",
    "                'key': 'FFmpegExtractAudio',\n",
    "                'preferredcodec': 'wav',\n",
    "                'preferredquality': '192',\n",
    "            }],\n",
    "            'logger': cls.MyLogger(),\n",
    "            'progress_hooks': [cls.my_hook],\n",
    "        }\n",
    "        with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
    "            ydl.download([url])\n",
    "\n",
    "    @staticmethod\n",
    "    def my_hook(d):\n",
    "        if d['status'] == 'finished':\n",
    "            print('Done downloading, now converting ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'out.wav'\n",
    "if not os.path.exists(filename):\n",
    "    dlr = Downloader()\n",
    "    dlr.download('https://www.youtube.com/watch?v=8rJu-eltak0', filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import torch\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "class Wave2Vec2:\n",
    "    def __init__(self, pretrained_model_name_or_path=\"facebook/wav2vec2-base-960h\"):\n",
    "        self.tokenizer = Wav2Vec2Tokenizer.from_pretrained(pretrained_model_name_or_path)\n",
    "        self.model = Wav2Vec2ForCTC.from_pretrained(pretrained_model_name_or_path)\n",
    "        self.device = torch.device('cuda')\n",
    "        self.model.to(self.device)\n",
    "        print(\"[INFO] model initialized..\")\n",
    "        \n",
    "    def load_wav_file(self, filename):\n",
    "        speech, rate = librosa.load(filename,sr=16000)\n",
    "        encoded_audio = self.tokenizer(speech, return_tensors = 'pt').input_values\n",
    "        encoded_audio = encoded_audio.to(self.device)\n",
    "        print(\"[INFO] wav file vectorized..\")\n",
    "        return encoded_audio\n",
    "    \n",
    "    def predict(self, encoded_audio, BATCH_SIZE=64,ignoreLast=False):\n",
    "        try:\n",
    "            SPILT_SIZE = encoded_audio.shape[1] // (BATCH_SIZE-1)\n",
    "            batches = torch.split(encoded_audio,SPILT_SIZE, dim=1)\n",
    "            print(f\"[INFO] split data into batches with SPILT_SIZE:{SPILT_SIZE}\")\n",
    "            if ignoreLast:\n",
    "                transcriptions = [self.__predict(batch, self.model, self.tokenizer) \\\n",
    "                    for batch in tqdm(batches[:-1])]\n",
    "            else:\n",
    "                transcriptions = [self.__predict(batch, self.model, self.tokenizer) \\\n",
    "                    for batch in tqdm(batches[:])]\n",
    "            print(\"[INFO] prediction done\")\n",
    "            return transcriptions  \n",
    "            \n",
    "        except RuntimeError as e:\n",
    "            if \"CUDA out of memory\" in str(e):\n",
    "                print(f\"CUDA out of memory...Try to increase batch size param or restart kernel\")\n",
    "            elif \"Kernel size can't greater than actual input size\" in str(e):\n",
    "                print(f\"Kernel size issue...Try to set ignoreLast to True\")\n",
    "        \n",
    "            print(e)\n",
    "            \n",
    "            return -1\n",
    "\n",
    "    @staticmethod\n",
    "    def __predict(batch, model, tokenizer):\n",
    "        with torch.no_grad():\n",
    "            logits = model(batch).logits\n",
    "            predicted_ids = torch.argmax(logits, dim=-1)\n",
    "            transcription = tokenizer.decode(predicted_ids[0])\n",
    "        return transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
      "The class this function is called from is 'Wav2Vec2Tokenizer'.\n",
      "c:\\Users\\Kaikai\\miniconda3\\envs\\nlp_py37\\lib\\site-packages\\transformers\\models\\wav2vec2\\tokenization_wav2vec2.py:757: FutureWarning: The class `Wav2Vec2Tokenizer` is deprecated and will be removed in version 5 of Transformers. Please use `Wav2Vec2Processor` or `Wav2Vec2CTCTokenizer` instead.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model initialized..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kaikai\\miniconda3\\envs\\nlp_py37\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] wav file vectorized..\n"
     ]
    }
   ],
   "source": [
    "cls = Wave2Vec2(\"facebook/wav2vec2-large-robust-ft-libri-960h\")\n",
    "encoded_audio = cls.load_wav_file(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] split data into batches with SPILT_SIZE:744512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:27<00:00,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] prediction done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transcriptions = cls.predict(encoded_audio, 32,ignoreLast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1516\\1215706581.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# stich back transcriptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfull_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{i}: {t}\"\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtranscriptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# print(full_text)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "# stich back transcriptions\n",
    "full_text = f\"\\n\".join(f\"{i}: {t}\" for i,t in enumerate(transcriptions)) \n",
    "# print(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_text_filename = \"output.txt\"\n",
    "if not os.path.exists(output_text_filename):\n",
    "    #make file\n",
    "    ...\n",
    "\n",
    "with open(output_text_filename,'w') as f:\n",
    "    f.write(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regex 2022.6.2: Fri Jun 17 20:54:51 2022\n",
      "certifi 2022.5.18.1: Fri Jun 17 20:54:51 2022\n",
      "pytz 2022.1: Fri Jun 17 20:54:51 2022\n",
      "youtube-dl 2021.12.17: Fri Jun 17 20:54:51 2022\n",
      "pywin32 302: Fri Jun 17 20:54:51 2022\n",
      "setuptools 61.2.0: Fri Jun 17 20:54:51 2022\n",
      "cryptography 37.0.1: Fri Jun 17 20:54:51 2022\n",
      "pyzmq 22.3.0: Fri Jun 17 20:54:51 2022\n",
      "pyOpenSSL 22.0.0: Fri Jun 17 20:54:51 2022\n",
      "attrs 21.4.0: Fri Jun 17 20:54:51 2022\n",
      "argon2-cffi 21.3.0: Fri Jun 17 20:54:51 2022\n",
      "packaging 21.3: Fri Jun 17 20:54:51 2022\n",
      "pip 21.2.4: Fri Jun 17 20:54:51 2022\n",
      "argon2-cffi-bindings 21.2.0: Fri Jun 17 20:54:51 2022\n",
      "Pillow 9.0.1: Fri Jun 17 20:54:51 2022\n",
      "ipython 7.31.1: Fri Jun 17 20:54:51 2022\n",
      "ipywidgets 7.6.5: Fri Jun 17 20:54:51 2022\n",
      "jupyter-client 7.2.2: Fri Jun 17 20:54:51 2022\n",
      "ipykernel 6.9.1: Fri Jun 17 20:54:51 2022\n",
      "notebook 6.4.11: Fri Jun 17 20:54:51 2022\n",
      "nbconvert 6.4.4: Fri Jun 17 20:54:51 2022\n",
      "jupyter-console 6.4.3: Fri Jun 17 20:54:51 2022\n",
      "tornado 6.1: Fri Jun 17 20:54:51 2022\n",
      "PyYAML 6.0: Fri Jun 17 20:54:51 2022\n",
      "nbformat 5.3.0: Fri Jun 17 20:54:51 2022\n",
      "qtconsole 5.3.0: Fri Jun 17 20:54:51 2022\n",
      "importlib-resources 5.2.0: Fri Jun 17 20:54:51 2022\n",
      "decorator 5.1.1: Fri Jun 17 20:54:51 2022\n",
      "traitlets 5.1.1: Fri Jun 17 20:54:51 2022\n",
      "tqdm 4.64.0: Fri Jun 17 20:54:51 2022\n",
      "fonttools 4.25.0: Fri Jun 17 20:54:51 2022\n",
      "transformers 4.20.0: Fri Jun 17 20:54:51 2022\n",
      "sip 4.19.13: Fri Jun 17 20:54:51 2022\n",
      "importlib-metadata 4.11.3: Fri Jun 17 20:54:51 2022\n",
      "beautifulsoup4 4.11.1: Fri Jun 17 20:54:51 2022\n",
      "jupyter-core 4.10.0: Fri Jun 17 20:54:51 2022\n",
      "jsonschema 4.4.0: Fri Jun 17 20:54:51 2022\n",
      "typing-extensions 4.1.1: Fri Jun 17 20:54:51 2022\n",
      "bleach 4.1.0: Fri Jun 17 20:54:51 2022\n",
      "zipp 3.8.0: Fri Jun 17 20:54:51 2022\n",
      "filelock 3.7.1: Fri Jun 17 20:54:51 2022\n",
      "widgetsnbextension 3.5.2: Fri Jun 17 20:54:51 2022\n",
      "matplotlib 3.5.1: Fri Jun 17 20:54:51 2022\n",
      "idna 3.3: Fri Jun 17 20:54:51 2022\n",
      "threadpoolctl 3.1.0: Fri Jun 17 20:54:51 2022\n",
      "prompt-toolkit 3.0.20: Fri Jun 17 20:54:51 2022\n",
      "pyparsing 3.0.4: Fri Jun 17 20:54:51 2022\n",
      "Jinja2 3.0.3: Fri Jun 17 20:54:51 2022\n",
      "requests 2.27.1: Fri Jun 17 20:54:51 2022\n",
      "pycparser 2.21: Fri Jun 17 20:54:51 2022\n",
      "fastjsonschema 2.15.1: Fri Jun 17 20:54:51 2022\n",
      "Pygments 2.11.2: Fri Jun 17 20:54:51 2022\n",
      "python-dateutil 2.8.2: Fri Jun 17 20:54:51 2022\n",
      "numexpr 2.8.1: Fri Jun 17 20:54:51 2022\n",
      "mkl-service 2.4.0: Fri Jun 17 20:54:51 2022\n",
      "soupsieve 2.3.1: Fri Jun 17 20:54:51 2022\n",
      "audioread 2.1.9: Fri Jun 17 20:54:51 2022\n",
      "MarkupSafe 2.1.1: Fri Jun 17 20:54:51 2022\n",
      "charset-normalizer 2.0.4: Fri Jun 17 20:54:51 2022\n",
      "pywinpty 2.0.2: Fri Jun 17 20:54:51 2022\n",
      "QtPy 2.0.1: Fri Jun 17 20:54:51 2022\n",
      "urllib3 1.26.9: Fri Jun 17 20:54:51 2022\n",
      "numpy 1.21.5: Fri Jun 17 20:54:51 2022\n",
      "six 1.16.0: Fri Jun 17 20:54:51 2022\n",
      "cffi 1.15.0: Fri Jun 17 20:54:51 2022\n",
      "torch 1.11.0: Fri Jun 17 20:54:51 2022\n",
      "Send2Trash 1.8.0: Fri Jun 17 20:54:51 2022\n",
      "scipy 1.7.3: Fri Jun 17 20:54:51 2022\n",
      "PySocks 1.7.1: Fri Jun 17 20:54:51 2022\n",
      "pooch 1.6.0: Fri Jun 17 20:54:51 2022\n",
      "nest-asyncio 1.5.5: Fri Jun 17 20:54:51 2022\n",
      "debugpy 1.5.1: Fri Jun 17 20:54:51 2022\n",
      "pandocfilters 1.5.0: Fri Jun 17 20:54:51 2022\n",
      "appdirs 1.4.4: Fri Jun 17 20:54:51 2022\n",
      "kiwisolver 1.4.2: Fri Jun 17 20:54:51 2022\n",
      "pandas 1.3.5: Fri Jun 17 20:54:51 2022\n",
      "Bottleneck 1.3.4: Fri Jun 17 20:54:51 2022\n",
      "mkl-fft 1.3.1: Fri Jun 17 20:54:51 2022\n",
      "mkl-random 1.2.2: Fri Jun 17 20:54:51 2022\n",
      "munkres 1.1.4: Fri Jun 17 20:54:51 2022\n",
      "joblib 1.1.0: Fri Jun 17 20:54:51 2022\n",
      "win-inet-pton 1.1.0: Fri Jun 17 20:54:51 2022\n",
      "scikit-learn 1.0.2: Fri Jun 17 20:54:51 2022\n",
      "jupyter 1.0.0: Fri Jun 17 20:54:51 2022\n",
      "jupyterlab-widgets 1.0.0: Fri Jun 17 20:54:51 2022\n",
      "numba 0.55.2: Fri Jun 17 20:54:51 2022\n",
      "llvmlite 0.38.1: Fri Jun 17 20:54:51 2022\n",
      "wheel 0.37.1: Fri Jun 17 20:54:51 2022\n",
      "jedi 0.18.1: Fri Jun 17 20:54:51 2022\n",
      "pyrsistent 0.18.0: Fri Jun 17 20:54:51 2022\n",
      "prometheus-client 0.13.1: Fri Jun 17 20:54:51 2022\n",
      "terminado 0.13.1: Fri Jun 17 20:54:51 2022\n",
      "tokenizers 0.12.1: Fri Jun 17 20:54:51 2022\n",
      "torchvision 0.12.0: Fri Jun 17 20:54:51 2022\n",
      "torchaudio 0.11.0: Fri Jun 17 20:54:51 2022\n",
      "cycler 0.11.0: Fri Jun 17 20:54:51 2022\n",
      "SoundFile 0.10.3.post1: Fri Jun 17 20:54:51 2022\n",
      "librosa 0.9.1: Fri Jun 17 20:54:51 2022\n",
      "mistune 0.8.4: Fri Jun 17 20:54:51 2022\n",
      "parso 0.8.3: Fri Jun 17 20:54:51 2022\n",
      "pickleshare 0.7.5: Fri Jun 17 20:54:51 2022\n",
      "defusedxml 0.7.1: Fri Jun 17 20:54:51 2022\n",
      "brotlipy 0.7.0: Fri Jun 17 20:54:51 2022\n",
      "huggingface-hub 0.7.0: Fri Jun 17 20:54:51 2022\n",
      "nbclient 0.5.13: Fri Jun 17 20:54:51 2022\n",
      "webencodings 0.5.1: Fri Jun 17 20:54:51 2022\n",
      "testpath 0.5.0: Fri Jun 17 20:54:51 2022\n",
      "colorama 0.4.4: Fri Jun 17 20:54:51 2022\n",
      "entrypoints 0.4: Fri Jun 17 20:54:51 2022\n",
      "wcwidth 0.2.5: Fri Jun 17 20:54:51 2022\n",
      "resampy 0.2.2: Fri Jun 17 20:54:51 2022\n",
      "wincertstore 0.2: Fri Jun 17 20:54:51 2022\n",
      "backcall 0.2.0: Fri Jun 17 20:54:51 2022\n",
      "ipython-genutils 0.2.0: Fri Jun 17 20:54:51 2022\n",
      "jupyterlab-pygments 0.1.2: Fri Jun 17 20:54:51 2022\n",
      "matplotlib-inline 0.1.2: Fri Jun 17 20:54:51 2022\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources, os, time\n",
    "\n",
    "for package in pkg_resources.working_set:\n",
    "    print(\"%s: %s\" % (package, time.ctime(os.path.getctime(package.location))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('nlp_py37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "653cedd06a0483d0c9fdb2edfc8833b6e5af203742e4672e031d9c20ec6374f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
