{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
      "The class this function is called from is 'Wav2Vec2Tokenizer'.\n",
      "c:\\Users\\Kaikai\\miniconda3\\envs\\nlp_py37\\lib\\site-packages\\transformers\\models\\wav2vec2\\tokenization_wav2vec2.py:757: FutureWarning: The class `Wav2Vec2Tokenizer` is deprecated and will be removed in version 5 of Transformers. Please use `Wav2Vec2Processor` or `Wav2Vec2CTCTokenizer` instead.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import torch\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer\n",
    "\n",
    "# tokenizer = Wav2Vec2Tokenizer.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "# model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "tokenizer = Wav2Vec2Tokenizer.from_pretrained(\"facebook/wav2vec2-large-robust-ft-libri-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-robust-ft-libri-960h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import youtube_dl  \n",
    "youtube_dl.downloader()  \n",
    "youtube-dl --extract-audio --audio-format wav -o 'ONEPIECE.wav' 'https://www.youtube.com/watch?v=KM8tNu1lBhU'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import youtube_dl\n",
    "\n",
    "class MyLogger(object):\n",
    "    def debug(self, msg):\n",
    "        pass\n",
    "    def warning(self, msg):\n",
    "        pass\n",
    "    def error(self, msg):\n",
    "        print(msg)\n",
    "\n",
    "def my_hook(d):\n",
    "    if d['status'] == 'finished':\n",
    "        print('Done downloading, now converting ...')\n",
    "\n",
    "ydl_opts = {\n",
    "    'format': 'bestaudio/best',\n",
    "    'postprocessors': [{\n",
    "        'key': 'FFmpegExtractAudio',\n",
    "        'preferredcodec': 'wav',\n",
    "        'preferredquality': '192',\n",
    "    }],\n",
    "    'logger': MyLogger(),\n",
    "    'progress_hooks': [my_hook],\n",
    "}\n",
    "with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
    "    ydl.download(['https://www.youtube.com/watch?v=dJAoK5zK36M'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"English Audio Speech-to-Text Transcript with Hugging Face _ Python NLP-dJAoK5zK36M.wav\"\n",
    "device = torch.device('cuda')\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, torch.Size([1, 157353]), torch.Size([1, 10]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorise input audio data\n",
    "speech, rate = librosa.load(filename,sr=16000)\n",
    "input_values = tokenizer(speech, return_tensors = 'pt').input_values\n",
    "input_values = input_values.to(device)\n",
    "\n",
    "SPILT_SIZE = input_values.shape[1] // (BATCH_SIZE-1)\n",
    "\n",
    "batches = torch.split(input_values,SPILT_SIZE, dim=1)\n",
    "len(batches), batches[0].shape, batches[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import torch.nn as nn\n",
    "# os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']='0,1'\n",
    "# os.environ['PYTORCH_CUDA_ALLOC_CONF']='max_split_size_mb:128'\n",
    "# # os.environ['PYTORCH_NO_CUDA_MEMORY_CACHING']='1'\n",
    "# print(os.environ['PYTORCH_CUDA_ALLOC_CONF'])\n",
    "# # print(os.environ['PYTORCH_NO_CUDA_MEMORY_CACHING'])``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 <torch.cuda.device object at 0x00000230524B2148> NVIDIA GeForce GTX 1070\n",
      "NVIDIA GeForce GTX 1070\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |   38912 KB |   38912 KB |   38912 KB |       0 B  |\n",
      "|       from large pool |   38912 KB |   38912 KB |   38912 KB |       0 B  |\n",
      "|       from small pool |       0 KB |       0 KB |       0 KB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |   38912 KB |   38912 KB |   38912 KB |       0 B  |\n",
      "|       from large pool |   38912 KB |   38912 KB |   38912 KB |       0 B  |\n",
      "|       from small pool |       0 KB |       0 KB |       0 KB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |   38912 KB |   38912 KB |   38912 KB |       0 B  |\n",
      "|       from large pool |   38912 KB |   38912 KB |   38912 KB |       0 B  |\n",
      "|       from small pool |       0 KB |       0 KB |       0 KB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       1    |       1    |       1    |       0    |\n",
      "|       from large pool |       1    |       1    |       1    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       1    |       1    |       1    |       0    |\n",
      "|       from large pool |       1    |       1    |       1    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       1    |       1    |       1    |       0    |\n",
      "|       from large pool |       1    |       1    |       1    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.device_count(), \\\n",
    "torch.cuda.device(0), \\\n",
    "torch.cuda.get_device_name(0))\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "    \n",
    "# print(torch.cuda.max_memory_cached(device=None))\n",
    "# print(torch.cuda.memory_allocated(device=None))\n",
    "# print(torch.cuda.memory_stats(device=None))\n",
    "print(torch.cuda.memory_summary(device=0, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = nn.DataParallel(model.cuda())\n",
    "# model = nn.DataParallel(model.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(batch, model):\n",
    "    with torch.no_grad():\n",
    "        logits = model(batch).logits\n",
    "        predicted_ids = torch.argmax(logits, dim=-1)\n",
    "        transcription = tokenizer.decode(predicted_ids[0])\n",
    "    return transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HAY FRENCH WELCOME TO ON LITTLE CODEN WHAT IF I TELL YOU THAT YOU CAN ACTUALLY DO SPEECH TRANSCRIPTION THE SAME WAY YOU DO ANEL PY WITH HUGGING FACE TRANSFORMERS E',\n",
       " \"S THAT IS A REALITY THAT HUGGING FACE TRANSFORMER'S LATEST UPTATIS GOD IN THE LATEST TRANSFORMERS SUBDAT HUGGING FACE HAS ADDED A THE VERY POPULAR FACE BOUQUES MODEL WAVE T\",\n",
       " 'WEK SO WAVTOO WEK LETS YOU OR AT LEAST I SHOULD SAY THAT THE HUGGING FACE AP OF WAVTOO WEK LETS YOU JUST GIVE HER AN AUDIO FILE AND THEN GET HER TRANSCRIPTERD',\n",
       " \"ENGLISH TRANSCRIPTION OUT OFFERD SO CURRENTLY AS FUR AS I KNOW THESE MORAL WORKS FINE FOR ENGLISH BUT I DONT NOW WHETHER THERE IS ANY OTHER LANGUAGE THAT IS AVAILABLE FOR THIS THING SO LET'S QUICKLY GO AHEAD AND THEN SEE HOW\",\n",
       " \"WE CAN DO SPEECH TRANSCRIPTION WITH HUGGING FIST TRANSFORMER'S MODEL THE FIRST SHIM THAT WE HAVE TO DO IS I'M UNUNDER TO GIVE YOU A LITTLE BIT MORE CONTEXT\",\n",
       " 'IHAVE NOT EVENT SWHICH DON MY AM GEPW ENVIRNMENT A GEPW OR ENVIROMNMENT SOME GOOD WOUL DO THIS ON SEEPE AND YOU WOULD ACTUALLY SEE ON LIFE HOW MUCH',\n",
       " \"ISTHE A SPEED THAT IS REQUIRED FOR THIS THING AND E I'M GOING TO USE A VERY POPULAR LINE FROM BARTMAN FOR THISE RECCORDING AND LET ME PLAY THAT FOR YOU SO\",\n",
       " 'WHEN I PLAY THIS YOU WILL BE ABLE TO HEAR IT LIVE LONG ENOGH TO SEE YOURSELF BECOME A VILLAIN YOU EITHER DIE A HERO',\n",
       " \"OR YOU LIVE WIL  O TO SEE YOURSELF BECIME TE BILLING THE AUDIO TRANSCRIP O OUR AUDIO FELE THAT WE'RE GOING TO TANSCRIPT AND PROBABLY EVERYONE KNOWS THIS LINE BY HEART\",\n",
       " \"SO THE FIRST STEP THAT WE HAVE TO DO IS WE HAVE TO INSTALL HUGGINGFACED TRANSFORMER'S LIBRARY SO PIP INSTALLED THE TRANSFORMERS LIBRARY ONCE YOU INSTALL THAT LIBRARY A WE ARE INTO USE LI\",\n",
       " 'BROSER FOR E THE MANAGING THE AUDIO PIL EXACTING AUDIO FIL AND THEN TORC AM PITOS AND THEN WE HWE HAVE WE NEED TO A',\n",
       " 'PLASSES FROM OR TRANSFORMERS ONE IS WAVE TO WAK TO FOR C T C AND WAVE TO WAK TO TOKONIZER SO AS YOU CAN SEE ON THE HUGGING FACED PAGE IT SAYS WAVE',\n",
       " 'WIK VICTO MODEL WAS TRAINED USING A C T S CONNECTIONIST TEMPORO CLASSIFICATION SO THE MODEL OUTPUT HAS TO BE DECORDED WITH A WAVE TO ER WE',\n",
       " \"TO VECTOT ORGANIZER AND THAT'S WHAT WE WAINT TO DO SO LET'S LOOK AT STEP ONE BY ONE THE FIRST STEP IS TO DOWNLOAD THE PREE TRAINED MODELS SO LETS DOWNLOD PRE\",\n",
       " \"TRAINED MODELS SO LET'S DOWNLOAD PRETRAINED MODELS AND A YOU CAN SEE THAT THE MODALS HAVE BEEN DOWNLOADED SO THE OTHER THING PROBABLY WE NEED TO KNOW HERE IS\",\n",
       " 'THE AUDIOFILE OR THE PRE TRAINED MODEL THAT WE HAVE DOWNLOADED HERE USES OF SIXTEEN THOUSAND A HURDS SO THE AUDIO FILE THAT WE NEED HAS T',\n",
       " \"O BE SAMPLED TO SIXTEEN THOUSAND HERDS SO THAT'S WANTING SO IN THIS CASE I'VE ACTUALLY USED OUDECITY TO CONVERT THAT AUDIO FILE TO SIXTEEN THOUSAND HERDS SO IT'S THERE AND OTHERWISE YOU WOULN'T NED A\",\n",
       " 'LITTLE BIT MORE COMPUTATION POWER TO CONVERT OR RESAMPLE IT SO YOU CAN USE ANY TOOL THAT YOU HAVE GOT A ON YOUR MACHINE TO CONVERT IT EVEN THAT COULD BE YOUNO ANY ONLIN TO WA',\n",
       " \"YOU COULD CONVERT AN AUDIOFILE FROM ONE FORMER TO ANOTHER FORMET SO IN THIS CASE I'VE JUST ALREADY CONNORTED IT SO I DON'T HAVE ANY PROBLEM SO I'M GOING TO LOAD THE AUDIO FILE HERE US\",\n",
       " \"ING LIBERALS OR OT LORD UNDER THE FILE NAME AND I'M SAYING THET MY SAMPLE RATE SHOULD BE SIXTEEN THOUSAND HURTS SO THIS IS PUT INTO SPEECH AND RATE AND RAE WOULD HAVE\",\n",
       " \"THERAD OFFERED NEXT I'M JUST PREVEVING THE AUDIOFILE LIKE I PREVIEWED BEFORE SO IN CASE IF YOU WANT ONE TIME LAST\",\n",
       " 'WO W O TE SE YOUSELF BEKOM O GOIN SHOULD THE TAT LINE AND YOU COULD SEE THAT THERE IS A LITTLE BIT OF BACKGROUND O MUSIC AS WELL AND',\n",
       " 'DE WE ARE TRYING TO DOWNLOAD THAT SO THE NEXT THING THAT WE NEED IS A WE NEED TO WE NEED TO TAKE INPUT VALUES SO INPUT VALUES',\n",
       " 'IS EQUAL TO TOKONIZER WE ARE PASSING ON THIS ORDY OF HEALL THAT WE GOT HERE THIS SPEECH IN THIS CASE TO THE TOKENIZER AND  WE ARE SAYING THAT WE WANT THE TINZERS T',\n",
       " \"O BE IN PI DODCH FORNIGHT SO LET'S RUN THIS SPEECH IS NOT AVAILABLE I'M SURE I HAVE NOT DUNED THIS EN DRAT IS SIXTEEN THOUSAND\",\n",
       " \"COOL AND THEN LET'S RUN THIS NOWLIKE I SAID WE'RE TILLING IT TO GIVE US THE OR TENZERS IN THE PI DOCH FORM AND NOW YOU CAN ACTUALLY SEE THE DANGOR\",\n",
       " \"AND NOW WHAT WE'RE GETTING IS WEARE TRYING TO GET THE LODGIT O WHICH IS THE NON NORMALLY'S PREDICTED VALUES SO IN A TYPICAL MULTICLAS CLASSIFICATION PROBLEM SO YOU W\",\n",
       " 'ULD GET ATHER VALUE SO IF I IF I JUST E PRINT LODGETS YOU WILL PROBABLY SEE THER NONORMALISED VALUES AND FROM THIS WHAT WE CAN ACTUALLY DO IS WE CAN P',\n",
       " 'ASS IT ON TO A SOFT MAX AND THEN WE CAN ACTUALLY GET THE PREDICTED VALUES AND THIS PREDICTED IDEA WHICH IS NOT RECORRED PROBABLY AND FROM THIS A PREDICTED IDES',\n",
       " \"WE ARE GOING TO KNOW PAS IT OUN TO THE TOKONIZER DECOD AND THEN WE ARE GOING TO GET THE TRANSCRIPTION THE SAME THING THAT THEY'VE MENTIONED HERE SO AFTER ALL WE DO ALL THESE THINGS WE HAVE TO PASSIT ON\",\n",
       " 'TO THE TOKONIZER THE CULD AND THEN WE ARE GOING TO GET THE TRANSCRIPTION OUT OF IT SO LET ME FAS TOKONIZE IT AND THEN NOW PRINT IT',\n",
       " 'AND YOU CAN SEE THAT IT SAYS YOU EITHER DIE A HERO OR YOU LIVE LONG ENOUGH TO SEE YOURSELF BECOME THE VILLAIN STRAIT AS EXACTLY MAN MACH THE',\n",
       " 'TEXT THE AUDIO AND THEN IT HAS GIVEN YOU THE TRANSCRIPT AND THAT IS THE BEAUTY OF WAVETOWAKE AND ACTUALLY TO BE HONEST IT HAS BEEN MADE MUCH MUCH SIMPLER AND THANKS TO',\n",
       " \"UGGING FACE FOR INCLUDING THIS IN THE TRANSFORMER'S LIBRARY NOW YOU DON'T NEED TO ACTUALLY WONDER HOW TO DO THIS OR WHAT TO DO THIS THING YOU CAN SIMPLY SIMPLY USE I THINK HOW MANY L\",\n",
       " 'ENCE WE HAVE DONE SO WE HAVE DONE PROBABLY A ONE ONE OR SAIL FOR A DOWNLOADING A THE MODEL SOP LIKE ONE TOKONI THER ON',\n",
       " 'MODEL OR TWO LINES OF CORENT IN READING THE FILE THREE LINES OF THE COD AND THEN WE HAVE LIKE IN LESS THAN TEN NIGTS OF THE CORD WE HAVE ACTUALLY SUCCESSFULLY BUILT A SPEECH TRANSCRIPT',\n",
       " 'AE FOR ENGLISH LANGUAGE USING A PRE TRAINED MODEL AND I WOULD LIKE TO ALSO PILOT THE FACT THAT NOW IF YOU ACTUALLY LISTEN TO THIS OUDIOR IF YOUR F',\n",
       " \"MILIAR WITH THE MOVI DARKNIGHT YOU WOULD HAVE PROBABLY SEEN THIS THIS A BEING SAID BY A BADMAN O BADMAN'S VOICE BUT WHEN I TRIED WITH BADMAN'S VOICE OR THE\",\n",
       " \"E HEAVY VOICE IT DIDN'T ACTUALLY TRANSCRIPT PROPERLY SO THIS IS A VOICE FROM HARVY DINSHO THIS IS SLIGHTLY A CLEARER THAN BARTMAN'S VOICE AND THAT IS ANOTHER THING A\",\n",
       " \"AND WHILE YOU WHILE WE HAVE OUNO SUCCESSFULLY TRIED ON GUGUL KOLA BUT IF YOU DON'T WANT TO TRY IT ON GUBL KOLAB YOU CAN ALSO TRY IT ON HUGGING FAS'S ARM HUGGING\",\n",
       " \"IS ON WEBSIGHT WHERE THEY'VE GOT MODALS AND THEN YOU CAN TRY SO FOR EXAMPLE HERE YOU CAN GO AND THEN LOOK FOR WEVE TO WAK TOO AND\",\n",
       " \"HEN CLICK IT AND THEN YOU CAN ACTUALLY SELECT THE SPECE THAT YOU WANT OR IF YOU DON'T WANT TO PICK ANYTHING YOU CAN PICK A SAMPLE OUDIO SO LET'S PICK THE SAMPLE ODIO\",\n",
       " 'AND SPEAKING TO DAMP AUDIENCES BEFORE HE HAD TIME TO ANSWER A MUCH ENCUMBERED VERA BURST INTO THE ROOM WITH THE QUESTION I',\n",
       " \"AY KAYE NOW LET'S SEE IF THIS BEING TRANSCRIPED SO LIKE I SAID YOU CAN EITHER USE IT ON COLABOR YOU CAN EVEN DO IT ON YOUR OWN MACHI\",\n",
       " \"AND IN FACT FOR THAT MATTER I DIDN'T EVEN USE THE G P OR ANYTHING BUT A  LET'S SEE IN THIS CASE WHAT HAPPENS OR IT ALSO LATS OU RECORD FROM BROSER WHICH WE CAN ALSO T\",\n",
       " \"RIGHT SO LET' SELECT SPEECH TOO AND THEN SAY COMPUTE AND THIS IS USING HUGGING FISE OR A P A SO YOU CAN ACTUALLY SEE THE A PAS PRICING ON THEIR WEBSIT IF YOU WANT TO USE IT FOR CO\",\n",
       " 'MMERCIAL PURPOSE YOU CAN USE IT BEFORE HE HAD THE TIME TO ANSWER MUCH OR INCOMBERBURST INTO THE ROOM SO YOU CAN SEE THAT IT IS IT IS UNOGATING SO L',\n",
       " 'ICH FINALLY YOU TIED A CORD FROM BROWSER ONCE',\n",
       " 'SO PLI LET ME SE',\n",
       " 'LET ME SEE HOW WAS THAT HAPPENING',\n",
       " 'OKE I THINK PROBABLY DUE TO AM PERMISSIONS AR MY RECORD FROM BROSER AS NOT OKING FRIND SO LET ME TRY ONCE AGAIN',\n",
       " 'LET ME DRY FROM MY BROUSE',\n",
       " 'LET ME',\n",
       " \"RIVE FROM MY BROSER AND WHEN I TRY THIS THING IT'S OKAY IN MY INDIAN ACCENT IT SAYS LET ME DRIVE FROM MY BOUSER SO I WU\",\n",
       " 'ULD STILL GIVE IT A GOOD RATING THAT IT IS DOING A VERY GOOD JOB WHERE YOU CAN A YOU CAN ADD A ANYOGU AND THEN GET THIS PREACH TRANSCRIPT NOW THE POSSIBL',\n",
       " 'USE ARE ACTUALLY ENDLESS FOR EXAMPLE NOW THAT YOU YOU CAN ACTUALLY USE HUGGING FACE TRANSFORMER AND THE A PS SIMILAR WHAT YOU CAN SIMPLY RDUSE YOU CAN BUILD A STREAM LARD APPLICATION PROBABLY WILL DO IT IN A COUPLE OF',\n",
       " 'FER AUPCOMING VEDIOS WHERE WE CAN BUILD A STRIMLET APPLICATION AND THEN JUST PUT THE PREE TRAIN MODAL OVER THERE AND THEN SIMPLY GIVE UPLOAD ANY ODIOFILE AND THEN GET',\n",
       " \"Y TRANSLATED AND LIKE I SAID I DIDN'T EVEN SWITCH ON MY G P IT STILL SEEPYOU AND THEN YOU CAN SEE THAT HOW FAST IT HAS HAPPEN SO IT'S REALLY A GREAT THING AND THEN ONCE AGAIN THANKS SO MUCH FOR ER\",\n",
       " \"HUGGING FISTS FOR MAKING THIS AVAILABLE OMIKING THIS MODEL AVAILABLE ON TRANSFORMER'S LIBRARY WHICH HAS ALREADY BEEN A HEAVILY USED IN THE ENELOPY WORLD AND HAVING HAVING SUCH A\",\n",
       " 'SPEECH TRANSCRIPT MODEL WITTEN PART OF THE SAME ECO SYSTEM MAKES IT MUCH MUCH EASIER FOR ANYONE TO LEVRAGE THIS THING IF YOU WANT TO TRY THIS OUT I WOULD A LINK THIS O',\n",
       " 'GUGLE COLAB NOTE BOOK ON A AS PART OF THE UDUB DESCRIPTION PLEASE TAKE IT OT IN THE DESCRIPTION AND THEN TRY I TRY OUT YOUR OWN AUDIR AND THEN LET ME KNOW IN THE COMMON SECTION',\n",
       " 'HOW DID IT GO IF YOU HAVE ANY QUTIONS PLASE LET ME NOWN THE COMMON SECTION OTHERWISE I HOPE YOU FIND THIS VIDIO HELPFUL AND E  PLEASE GIVE A THUMSIP AND A SUBSCRIBE TO THE CHANNEL IF YOUHAVE NOT S',\n",
       " 'ARE THIS MEDIA WITH OTHERS SO THAT THEY CAN GET STARTED WITH THIS PROJECT LETS A SHARE THE KNOWLEDGE AND THEN A SHARE THE VALUES OF OPEN SOURCE SO TAKE CARE OF YOURSELF UNTIL NEXT RADIO SEE YOU']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transcribe audio data, ignoring last batch\n",
    "torch.cuda.empty_cache()\n",
    "model.to(device)\n",
    "transcriptions = [predict(batch,model) for batch in batches[:-1]]\n",
    "transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"0: HAY FRENCH WELCOME TO ON LITTLE CODEN WHAT IF I TELL YOU THAT YOU CAN ACTUALLY DO SPEECH TRANSCRIPTION THE SAME WAY YOU DO ANEL PY WITH HUGGING FACE TRANSFORMERS E\\n1: S THAT IS A REALITY THAT HUGGING FACE TRANSFORMER'S LATEST UPTATIS GOD IN THE LATEST TRANSFORMERS SUBDAT HUGGING FACE HAS ADDED A THE VERY POPULAR FACE BOUQUES MODEL WAVE T\\n2: WEK SO WAVTOO WEK LETS YOU OR AT LEAST I SHOULD SAY THAT THE HUGGING FACE AP OF WAVTOO WEK LETS YOU JUST GIVE HER AN AUDIO FILE AND THEN GET HER TRANSCRIPTERD\\n3: ENGLISH TRANSCRIPTION OUT OFFERD SO CURRENTLY AS FUR AS I KNOW THESE MORAL WORKS FINE FOR ENGLISH BUT I DONT NOW WHETHER THERE IS ANY OTHER LANGUAGE THAT IS AVAILABLE FOR THIS THING SO LET'S QUICKLY GO AHEAD AND THEN SEE HOW\\n4: WE CAN DO SPEECH TRANSCRIPTION WITH HUGGING FIST TRANSFORMER'S MODEL THE FIRST SHIM THAT WE HAVE TO DO IS I'M UNUNDER TO GIVE YOU A LITTLE BIT MORE CONTEXT\\n5: IHAVE NOT EVENT SWHICH DON MY AM GEPW ENVIRNMENT A GEPW OR ENVIROMNMENT SOME GOOD WOUL DO THIS ON SEEPE AND YOU WOULD ACTUALLY SEE ON LIFE HOW MUCH\\n6: ISTHE A SPEED THAT IS REQUIRED FOR THIS THING AND E I'M GOING TO USE A VERY POPULAR LINE FROM BARTMAN FOR THISE RECCORDING AND LET ME PLAY THAT FOR YOU SO\\n7: WHEN I PLAY THIS YOU WILL BE ABLE TO HEAR IT LIVE LONG ENOGH TO SEE YOURSELF BECOME A VILLAIN YOU EITHER DIE A HERO\\n8: OR YOU LIVE WIL  O TO SEE YOURSELF BECIME TE BILLING THE AUDIO TRANSCRIP O OUR AUDIO FELE THAT WE'RE GOING TO TANSCRIPT AND PROBABLY EVERYONE KNOWS THIS LINE BY HEART\\n9: SO THE FIRST STEP THAT WE HAVE TO DO IS WE HAVE TO INSTALL HUGGINGFACED TRANSFORMER'S LIBRARY SO PIP INSTALLED THE TRANSFORMERS LIBRARY ONCE YOU INSTALL THAT LIBRARY A WE ARE INTO USE LI\\n10: BROSER FOR E THE MANAGING THE AUDIO PIL EXACTING AUDIO FIL AND THEN TORC AM PITOS AND THEN WE HWE HAVE WE NEED TO A\\n11: PLASSES FROM OR TRANSFORMERS ONE IS WAVE TO WAK TO FOR C T C AND WAVE TO WAK TO TOKONIZER SO AS YOU CAN SEE ON THE HUGGING FACED PAGE IT SAYS WAVE\\n12: WIK VICTO MODEL WAS TRAINED USING A C T S CONNECTIONIST TEMPORO CLASSIFICATION SO THE MODEL OUTPUT HAS TO BE DECORDED WITH A WAVE TO ER WE\\n13: TO VECTOT ORGANIZER AND THAT'S WHAT WE WAINT TO DO SO LET'S LOOK AT STEP ONE BY ONE THE FIRST STEP IS TO DOWNLOAD THE PREE TRAINED MODELS SO LETS DOWNLOD PRE\\n14: TRAINED MODELS SO LET'S DOWNLOAD PRETRAINED MODELS AND A YOU CAN SEE THAT THE MODALS HAVE BEEN DOWNLOADED SO THE OTHER THING PROBABLY WE NEED TO KNOW HERE IS\\n15: THE AUDIOFILE OR THE PRE TRAINED MODEL THAT WE HAVE DOWNLOADED HERE USES OF SIXTEEN THOUSAND A HURDS SO THE AUDIO FILE THAT WE NEED HAS T\\n16: O BE SAMPLED TO SIXTEEN THOUSAND HERDS SO THAT'S WANTING SO IN THIS CASE I'VE ACTUALLY USED OUDECITY TO CONVERT THAT AUDIO FILE TO SIXTEEN THOUSAND HERDS SO IT'S THERE AND OTHERWISE YOU WOULN'T NED A\\n17: LITTLE BIT MORE COMPUTATION POWER TO CONVERT OR RESAMPLE IT SO YOU CAN USE ANY TOOL THAT YOU HAVE GOT A ON YOUR MACHINE TO CONVERT IT EVEN THAT COULD BE YOUNO ANY ONLIN TO WA\\n18: YOU COULD CONVERT AN AUDIOFILE FROM ONE FORMER TO ANOTHER FORMET SO IN THIS CASE I'VE JUST ALREADY CONNORTED IT SO I DON'T HAVE ANY PROBLEM SO I'M GOING TO LOAD THE AUDIO FILE HERE US\\n19: ING LIBERALS OR OT LORD UNDER THE FILE NAME AND I'M SAYING THET MY SAMPLE RATE SHOULD BE SIXTEEN THOUSAND HURTS SO THIS IS PUT INTO SPEECH AND RATE AND RAE WOULD HAVE\\n20: THERAD OFFERED NEXT I'M JUST PREVEVING THE AUDIOFILE LIKE I PREVIEWED BEFORE SO IN CASE IF YOU WANT ONE TIME LAST\\n21: WO W O TE SE YOUSELF BEKOM O GOIN SHOULD THE TAT LINE AND YOU COULD SEE THAT THERE IS A LITTLE BIT OF BACKGROUND O MUSIC AS WELL AND\\n22: DE WE ARE TRYING TO DOWNLOAD THAT SO THE NEXT THING THAT WE NEED IS A WE NEED TO WE NEED TO TAKE INPUT VALUES SO INPUT VALUES\\n23: IS EQUAL TO TOKONIZER WE ARE PASSING ON THIS ORDY OF HEALL THAT WE GOT HERE THIS SPEECH IN THIS CASE TO THE TOKENIZER AND  WE ARE SAYING THAT WE WANT THE TINZERS T\\n24: O BE IN PI DODCH FORNIGHT SO LET'S RUN THIS SPEECH IS NOT AVAILABLE I'M SURE I HAVE NOT DUNED THIS EN DRAT IS SIXTEEN THOUSAND\\n25: COOL AND THEN LET'S RUN THIS NOWLIKE I SAID WE'RE TILLING IT TO GIVE US THE OR TENZERS IN THE PI DOCH FORM AND NOW YOU CAN ACTUALLY SEE THE DANGOR\\n26: AND NOW WHAT WE'RE GETTING IS WEARE TRYING TO GET THE LODGIT O WHICH IS THE NON NORMALLY'S PREDICTED VALUES SO IN A TYPICAL MULTICLAS CLASSIFICATION PROBLEM SO YOU W\\n27: ULD GET ATHER VALUE SO IF I IF I JUST E PRINT LODGETS YOU WILL PROBABLY SEE THER NONORMALISED VALUES AND FROM THIS WHAT WE CAN ACTUALLY DO IS WE CAN P\\n28: ASS IT ON TO A SOFT MAX AND THEN WE CAN ACTUALLY GET THE PREDICTED VALUES AND THIS PREDICTED IDEA WHICH IS NOT RECORRED PROBABLY AND FROM THIS A PREDICTED IDES\\n29: WE ARE GOING TO KNOW PAS IT OUN TO THE TOKONIZER DECOD AND THEN WE ARE GOING TO GET THE TRANSCRIPTION THE SAME THING THAT THEY'VE MENTIONED HERE SO AFTER ALL WE DO ALL THESE THINGS WE HAVE TO PASSIT ON\\n30: TO THE TOKONIZER THE CULD AND THEN WE ARE GOING TO GET THE TRANSCRIPTION OUT OF IT SO LET ME FAS TOKONIZE IT AND THEN NOW PRINT IT\\n31: AND YOU CAN SEE THAT IT SAYS YOU EITHER DIE A HERO OR YOU LIVE LONG ENOUGH TO SEE YOURSELF BECOME THE VILLAIN STRAIT AS EXACTLY MAN MACH THE\\n32: TEXT THE AUDIO AND THEN IT HAS GIVEN YOU THE TRANSCRIPT AND THAT IS THE BEAUTY OF WAVETOWAKE AND ACTUALLY TO BE HONEST IT HAS BEEN MADE MUCH MUCH SIMPLER AND THANKS TO\\n33: UGGING FACE FOR INCLUDING THIS IN THE TRANSFORMER'S LIBRARY NOW YOU DON'T NEED TO ACTUALLY WONDER HOW TO DO THIS OR WHAT TO DO THIS THING YOU CAN SIMPLY SIMPLY USE I THINK HOW MANY L\\n34: ENCE WE HAVE DONE SO WE HAVE DONE PROBABLY A ONE ONE OR SAIL FOR A DOWNLOADING A THE MODEL SOP LIKE ONE TOKONI THER ON\\n35: MODEL OR TWO LINES OF CORENT IN READING THE FILE THREE LINES OF THE COD AND THEN WE HAVE LIKE IN LESS THAN TEN NIGTS OF THE CORD WE HAVE ACTUALLY SUCCESSFULLY BUILT A SPEECH TRANSCRIPT\\n36: AE FOR ENGLISH LANGUAGE USING A PRE TRAINED MODEL AND I WOULD LIKE TO ALSO PILOT THE FACT THAT NOW IF YOU ACTUALLY LISTEN TO THIS OUDIOR IF YOUR F\\n37: MILIAR WITH THE MOVI DARKNIGHT YOU WOULD HAVE PROBABLY SEEN THIS THIS A BEING SAID BY A BADMAN O BADMAN'S VOICE BUT WHEN I TRIED WITH BADMAN'S VOICE OR THE\\n38: E HEAVY VOICE IT DIDN'T ACTUALLY TRANSCRIPT PROPERLY SO THIS IS A VOICE FROM HARVY DINSHO THIS IS SLIGHTLY A CLEARER THAN BARTMAN'S VOICE AND THAT IS ANOTHER THING A\\n39: AND WHILE YOU WHILE WE HAVE OUNO SUCCESSFULLY TRIED ON GUGUL KOLA BUT IF YOU DON'T WANT TO TRY IT ON GUBL KOLAB YOU CAN ALSO TRY IT ON HUGGING FAS'S ARM HUGGING\\n40: IS ON WEBSIGHT WHERE THEY'VE GOT MODALS AND THEN YOU CAN TRY SO FOR EXAMPLE HERE YOU CAN GO AND THEN LOOK FOR WEVE TO WAK TOO AND\\n41: HEN CLICK IT AND THEN YOU CAN ACTUALLY SELECT THE SPECE THAT YOU WANT OR IF YOU DON'T WANT TO PICK ANYTHING YOU CAN PICK A SAMPLE OUDIO SO LET'S PICK THE SAMPLE ODIO\\n42: AND SPEAKING TO DAMP AUDIENCES BEFORE HE HAD TIME TO ANSWER A MUCH ENCUMBERED VERA BURST INTO THE ROOM WITH THE QUESTION I\\n43: AY KAYE NOW LET'S SEE IF THIS BEING TRANSCRIPED SO LIKE I SAID YOU CAN EITHER USE IT ON COLABOR YOU CAN EVEN DO IT ON YOUR OWN MACHI\\n44: AND IN FACT FOR THAT MATTER I DIDN'T EVEN USE THE G P OR ANYTHING BUT A  LET'S SEE IN THIS CASE WHAT HAPPENS OR IT ALSO LATS OU RECORD FROM BROSER WHICH WE CAN ALSO T\\n45: RIGHT SO LET' SELECT SPEECH TOO AND THEN SAY COMPUTE AND THIS IS USING HUGGING FISE OR A P A SO YOU CAN ACTUALLY SEE THE A PAS PRICING ON THEIR WEBSIT IF YOU WANT TO USE IT FOR CO\\n46: MMERCIAL PURPOSE YOU CAN USE IT BEFORE HE HAD THE TIME TO ANSWER MUCH OR INCOMBERBURST INTO THE ROOM SO YOU CAN SEE THAT IT IS IT IS UNOGATING SO L\\n47: ICH FINALLY YOU TIED A CORD FROM BROWSER ONCE\\n48: SO PLI LET ME SE\\n49: LET ME SEE HOW WAS THAT HAPPENING\\n50: OKE I THINK PROBABLY DUE TO AM PERMISSIONS AR MY RECORD FROM BROSER AS NOT OKING FRIND SO LET ME TRY ONCE AGAIN\\n51: LET ME DRY FROM MY BROUSE\\n52: LET ME\\n53: RIVE FROM MY BROSER AND WHEN I TRY THIS THING IT'S OKAY IN MY INDIAN ACCENT IT SAYS LET ME DRIVE FROM MY BOUSER SO I WU\\n54: ULD STILL GIVE IT A GOOD RATING THAT IT IS DOING A VERY GOOD JOB WHERE YOU CAN A YOU CAN ADD A ANYOGU AND THEN GET THIS PREACH TRANSCRIPT NOW THE POSSIBL\\n55: USE ARE ACTUALLY ENDLESS FOR EXAMPLE NOW THAT YOU YOU CAN ACTUALLY USE HUGGING FACE TRANSFORMER AND THE A PS SIMILAR WHAT YOU CAN SIMPLY RDUSE YOU CAN BUILD A STREAM LARD APPLICATION PROBABLY WILL DO IT IN A COUPLE OF\\n56: FER AUPCOMING VEDIOS WHERE WE CAN BUILD A STRIMLET APPLICATION AND THEN JUST PUT THE PREE TRAIN MODAL OVER THERE AND THEN SIMPLY GIVE UPLOAD ANY ODIOFILE AND THEN GET\\n57: Y TRANSLATED AND LIKE I SAID I DIDN'T EVEN SWITCH ON MY G P IT STILL SEEPYOU AND THEN YOU CAN SEE THAT HOW FAST IT HAS HAPPEN SO IT'S REALLY A GREAT THING AND THEN ONCE AGAIN THANKS SO MUCH FOR ER\\n58: HUGGING FISTS FOR MAKING THIS AVAILABLE OMIKING THIS MODEL AVAILABLE ON TRANSFORMER'S LIBRARY WHICH HAS ALREADY BEEN A HEAVILY USED IN THE ENELOPY WORLD AND HAVING HAVING SUCH A\\n59: SPEECH TRANSCRIPT MODEL WITTEN PART OF THE SAME ECO SYSTEM MAKES IT MUCH MUCH EASIER FOR ANYONE TO LEVRAGE THIS THING IF YOU WANT TO TRY THIS OUT I WOULD A LINK THIS O\\n60: GUGLE COLAB NOTE BOOK ON A AS PART OF THE UDUB DESCRIPTION PLEASE TAKE IT OT IN THE DESCRIPTION AND THEN TRY I TRY OUT YOUR OWN AUDIR AND THEN LET ME KNOW IN THE COMMON SECTION\\n61: HOW DID IT GO IF YOU HAVE ANY QUTIONS PLASE LET ME NOWN THE COMMON SECTION OTHERWISE I HOPE YOU FIND THIS VIDIO HELPFUL AND E  PLEASE GIVE A THUMSIP AND A SUBSCRIBE TO THE CHANNEL IF YOUHAVE NOT S\\n62: ARE THIS MEDIA WITH OTHERS SO THAT THEY CAN GET STARTED WITH THIS PROJECT LETS A SHARE THE KNOWLEDGE AND THEN A SHARE THE VALUES OF OPEN SOURCE SO TAKE CARE OF YOURSELF UNTIL NEXT RADIO SEE YOU\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stich back transcriptions\n",
    "full_text = f\"\\n\".join(f\"{i}: {t}\" for i,t in enumerate(transcriptions)) \n",
    "full_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('nlp_py37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "653cedd06a0483d0c9fdb2edfc8833b6e5af203742e4672e031d9c20ec6374f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
